{
    "description": "llama3 template",
    "prompt_input": [],
    "prompt_no_input": [
        "<|start_header_id|>user<|end_header_id|>\n\n{instruction}"
    ],
    "response_split": "<|start_header_id|>assistant<|end_header_id|>"
}